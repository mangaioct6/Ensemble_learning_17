{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d67c8",
   "metadata": {},
   "source": [
    "# Group Activity Week 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306b764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98fade85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv('../SupervisedML_13/diabetes.csv')\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0631161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,precision_score,recall_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "514fe76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 80.0 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       150\n",
      "           1       0.78      0.60      0.68        81\n",
      "\n",
      "    accuracy                           0.80       231\n",
      "   macro avg       0.79      0.76      0.77       231\n",
      "weighted avg       0.80      0.80      0.79       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = diabetes_df.iloc[:,:-1]\n",
    "y = diabetes_df.iloc[:,-1]\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=6, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "\n",
    "#estimator = model\n",
    "rf = RandomForestClassifier(n_estimators=200,random_state=42)\n",
    "\n",
    "rf = rf.fit(X_train, y_train)\n",
    "print('Accuracy Score',rf.score(X_test, y_test).round(2)*100,'%')\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c4f926",
   "metadata": {},
   "source": [
    "### 1. Write simple (straightforward) definitions for the following parameters for RandomForestClassifier  and indicate how they correlate with the precision and recall for the basic diabetes model we built in class. You will need to rerun the model multiple times to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125bfa0",
   "metadata": {},
   "source": [
    "### **1.n_estimator**- number of trees in the forest.\n",
    "\n",
    "   * It correlated **positively with precision** (precision increased if no of trees increased and decreased if no of trees reduced) and changed about 0.1 with each number increase.  \n",
    "   \n",
    "   * There is a **negative correlation between recall and n_estimator**. I have increased n_estimator from 20 to 100 and then 100 to 300, recall reduced about 0.02 and 0.01 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85f3ca0",
   "metadata": {},
   "source": [
    "### **2.max_depth** - the longest path between the root node and the leaf node\n",
    "\n",
    "* max_depth is **negatively correlated with precision**. I changed max_depth from 3 to 5. precision was reduced 0.02.\n",
    "\n",
    "* It is **positively correlated with recall**. It is increased 0.04 for the depth increased from 3 to 5 and then for 5 to 10 it is increased for 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854f646",
   "metadata": {},
   "source": [
    "### **3.min_samples_split** - the minimum number of samples required to split an internal node(default value is 2).\n",
    "\n",
    "* There is a **strong positive correlation between precision and min_samples_split**. When I increased min_samples_split from 5 to 200, I got an increment of 0.07 in precision. \n",
    "\n",
    "* Opposite to precision, **there is negative correlation with recall**. For the same amount of increase in min_samples_split, my recall reduced very well(0.18)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed4569",
   "metadata": {},
   "source": [
    "### **4.min_samples_leaf** -  specifies the minimum number of samples that should be present in the leaf node(default is 1).\n",
    "\n",
    "* There is a **strong positive correlation** between precision and min_samples_leaf. When I increased min_samples_leaf from 5 to 100, I got an increment of 0.13 in precision.\n",
    "\n",
    "* Opposite to precision, there is **negative correlation with recall**. For the same amount of increase in min_samples_leaf, my recall reduced very well(0.18)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d320fe1",
   "metadata": {},
   "source": [
    "### **5. min_weight_fraction_leaf** - the fraction of the input samples required to be at a leaf node. min_weight_fraction_leaf must in [0, 0.5]\n",
    "\n",
    "* It is **positively correlated with precision**. Great improvement in precision for each increment of 0.1. \n",
    "* It is **negatively correlated with recall**. For first increment of 0.1 in min_weight_fraction_leaf, our recall reduced 0.05, and for another increment of 0.1, recall is reduced for 0.09."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d13b3",
   "metadata": {},
   "source": [
    "### **6.max_leaf_nodes** - This hyperparameter sets a condition on the splitting of the nodes in the tree and hence restricts the growth of the tree. If this parameter value goes beyond 25, then tree starts to overfit.\n",
    "\n",
    "* Precision started decreasing if I increase max_leaf_node. So **its negative correlation**. Increment of 2 from max_leaf_nodes impacted our precision about 0.06.\n",
    "\n",
    "* Recall is **positively correlated with max_leaf_nodes**. We are getting improved recall from 0.37 to 0.44 for the same increment of max_leaf_nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f9ecc",
   "metadata": {},
   "source": [
    "### **7.min_impurity_decrease** - A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "\n",
    "* There is a **positive correlation with precision**. We are getting highest precision for min_impurity_decrease of 0.04.\n",
    "* There is a **negative correlation with recall**. We are getting very low recall for min_impurity_decrease of 0.04. So increasing min_impurity_decrease value is a bad idea for this diabetes dataset. Because we want good recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d342cfc",
   "metadata": {},
   "source": [
    "* Using my function, I did tuned my hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "354ab77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for n_estimator =  20 is 0.65\n",
      "Precision for n_estimator =  100 is 0.68\n",
      "Precision for n_estimator =  300 is 0.68\n",
      "Precision for n_estimator =  500 is 0.69\n"
     ]
    }
   ],
   "source": [
    "def estimator(n):\n",
    "    rf = RandomForestClassifier(n_estimators=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Precision for n_estimator = ',n, 'is',precision_score(y_test,predictions).round(2))\n",
    "    \n",
    "estimator(20)    \n",
    "estimator(100)\n",
    "estimator(300)\n",
    "estimator(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18afca57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for n_estimator =  20 is 0.6\n",
      "Recall for n_estimator =  100 is 0.58\n",
      "Recall for n_estimator =  300 is 0.57\n",
      "Recall for n_estimator =  500 is 0.57\n"
     ]
    }
   ],
   "source": [
    "def estimator(n):\n",
    "    rf = RandomForestClassifier(n_estimators=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Recall for n_estimator = ',n, 'is',recall_score(y_test,predictions).round(2))\n",
    "    \n",
    "estimator(20)\n",
    "estimator(100)\n",
    "estimator(300)\n",
    "estimator(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a1eb316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for max_depth =  3 is 0.7\n",
      "Precision for max_depth =  5 is 0.68\n",
      "Precision for max_depth =  10 is 0.69\n",
      "Precision for max_depth =  30 is 0.68\n"
     ]
    }
   ],
   "source": [
    "def max_depth(n):\n",
    "    rf = RandomForestClassifier(max_depth=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Precision for max_depth = ',n, 'is',precision_score(y_test,predictions).round(2))\n",
    "max_depth(3)\n",
    "max_depth(5)\n",
    "max_depth(10)\n",
    "max_depth(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d74615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for max_depth =  3 is 0.48\n",
      "Recall for max_depth =  5 is 0.52\n",
      "Recall for max_depth =  10 is 0.57\n",
      "Recall for max_depth =  30 is 0.58\n"
     ]
    }
   ],
   "source": [
    "def max_depth(n):\n",
    "    rf = RandomForestClassifier(max_depth=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Recall for max_depth = ',n, 'is',recall_score(y_test,predictions).round(2))\n",
    "max_depth(3)\n",
    "max_depth(5)\n",
    "max_depth(10)\n",
    "max_depth(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7c13103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for min_samples_split =  5 is 0.69\n",
      "Precision for min_samples_split =  50 is 0.69\n",
      "Precision for min_samples_split =  100 is 0.71\n",
      "Precision for min_samples_split =  200 is 0.76\n"
     ]
    }
   ],
   "source": [
    "def min_samples_split(n):\n",
    "    rf = RandomForestClassifier(min_samples_split=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Precision for min_samples_split = ',n, 'is',precision_score(y_test,predictions).round(2))\n",
    "min_samples_split(5)\n",
    "min_samples_split(50)\n",
    "min_samples_split(100)\n",
    "min_samples_split(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6483a754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for min_samples_split =  5 is 0.54\n",
      "Recall for min_samples_split =  50 is 0.53\n",
      "Recall for min_samples_split =  100 is 0.46\n",
      "Recall for min_samples_split =  200 is 0.36\n"
     ]
    }
   ],
   "source": [
    "def min_samples_split(n):\n",
    "    rf = RandomForestClassifier(min_samples_split=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Recall for min_samples_split = ',n, 'is',recall_score(y_test,predictions).round(2))\n",
    "min_samples_split(5)\n",
    "min_samples_split(50)\n",
    "min_samples_split(100)\n",
    "min_samples_split(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0335fa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for min_samples_leaf =  5 is 0.68\n",
      "Precision for min_samples_leaf =  50 is 0.69\n",
      "Precision for min_samples_leaf =  100 is 0.81\n"
     ]
    }
   ],
   "source": [
    "def min_samples_leaf(n):\n",
    "    rf = RandomForestClassifier(min_samples_leaf=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Precision for min_samples_leaf = ',n, 'is',precision_score(y_test,predictions).round(2))\n",
    "min_samples_leaf(5)\n",
    "min_samples_leaf(50)\n",
    "min_samples_leaf(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "38f4638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for min_samples_leaf =  5 is 0.53\n",
      "Recall for min_samples_leaf =  50 is 0.44\n",
      "Recall for min_samples_leaf =  100 is 0.31\n"
     ]
    }
   ],
   "source": [
    "def min_samples_leaf(n):\n",
    "    rf = RandomForestClassifier(min_samples_leaf=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Recall for min_samples_leaf = ',n, 'is',recall_score(y_test,predictions).round(2))\n",
    "min_samples_leaf(5)\n",
    "min_samples_leaf(50)\n",
    "min_samples_leaf(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6bc073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for min_weight_fraction_leaf =  0.1 is 0.69\n",
      "Precision for min_weight_fraction_leaf =  0.2 is 0.74\n",
      "Precision for min_weight_fraction_leaf =  0.3 is 0.78\n"
     ]
    }
   ],
   "source": [
    "def min_weight_fraction_leaf(n):\n",
    "    rf = RandomForestClassifier(min_weight_fraction_leaf=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Precision for min_weight_fraction_leaf = ',n, 'is',precision_score(y_test,predictions).round(2))\n",
    "min_weight_fraction_leaf(0.1)\n",
    "min_weight_fraction_leaf(0.2)\n",
    "min_weight_fraction_leaf(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2c409a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for min_weight_fraction_leaf =  0.1 is 0.47\n",
      "Recall for min_weight_fraction_leaf =  0.2 is 0.42\n",
      "Recall for min_weight_fraction_leaf =  0.3 is 0.31\n"
     ]
    }
   ],
   "source": [
    "def min_weight_fraction_leaf(n):\n",
    "    rf = RandomForestClassifier(min_weight_fraction_leaf=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Recall for min_weight_fraction_leaf = ',n, 'is',recall_score(y_test,predictions).round(2))\n",
    "min_weight_fraction_leaf(0.1)\n",
    "min_weight_fraction_leaf(0.2)\n",
    "min_weight_fraction_leaf(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93421b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for max_leaf_nodes =  3 is 0.79\n",
      "Precision for max_leaf_nodes =  5 is 0.71\n",
      "Precision for max_leaf_nodes =  10 is 0.7\n",
      "Precision for max_leaf_nodes =  20 is 0.69\n"
     ]
    }
   ],
   "source": [
    "def max_leaf_nodes(n):\n",
    "    rf = RandomForestClassifier(max_leaf_nodes=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Precision for max_leaf_nodes = ',n, 'is',precision_score(y_test,predictions).round(2))\n",
    "max_leaf_nodes(3)\n",
    "max_leaf_nodes(5)\n",
    "max_leaf_nodes(10)\n",
    "max_leaf_nodes(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f938e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for max_leaf_nodes =  3 is 0.37\n",
      "Recall for max_leaf_nodes =  5 is 0.44\n",
      "Recall for max_leaf_nodes =  10 is 0.48\n",
      "Recall for max_leaf_nodes =  20 is 0.51\n"
     ]
    }
   ],
   "source": [
    "def max_leaf_nodes(n):\n",
    "    rf = RandomForestClassifier(max_leaf_nodes=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Recall for max_leaf_nodes = ',n, 'is',recall_score(y_test,predictions).round(2))\n",
    "max_leaf_nodes(3)\n",
    "max_leaf_nodes(5)\n",
    "max_leaf_nodes(10)\n",
    "max_leaf_nodes(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68e8bbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for max_leaf_nodes =  0.002 is 0.73\n",
      "Precision for max_leaf_nodes =  0.03 is 0.84\n",
      "Precision for max_leaf_nodes =  0.04 is 0.89\n"
     ]
    }
   ],
   "source": [
    "def min_impurity_decrease(n):\n",
    "    rf = RandomForestClassifier(min_impurity_decrease=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Precision for min_impurity_decrease = ',n, 'is',precision_score(y_test,predictions).round(2))\n",
    "min_impurity_decrease(0.002)\n",
    "min_impurity_decrease(0.03)\n",
    "min_impurity_decrease(0.04)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "231ecee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for max_leaf_nodes =  0.002 is 0.53\n",
      "Recall for max_leaf_nodes =  0.03 is 0.33\n",
      "Recall for max_leaf_nodes =  0.04 is 0.2\n"
     ]
    }
   ],
   "source": [
    "def min_impurity_decrease(n):\n",
    "    rf = RandomForestClassifier(min_impurity_decrease=n,random_state=6)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('Recall for min_impurity_decrease = ',n, 'is',recall_score(y_test,predictions).round(2))\n",
    "min_impurity_decrease(0.002)\n",
    "min_impurity_decrease(0.03)\n",
    "min_impurity_decrease(0.04)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e327c59",
   "metadata": {},
   "source": [
    "\n",
    "#### Summarized Table \n",
    "\n",
    "\n",
    "\n",
    "|   Parameter            |    Correlation with Precision                  |     Correlation with Recall                   | \n",
    "|:----------------------:|:----------------------------------------------:|:---------------------------------------------:|\n",
    "|1.n_estimator           | correlated positively(0.01 value is increasing)|negatively correlated                          | \n",
    "|2. max_depth            | not correlated well, almost getting same value |positively correlated                          |  \n",
    "|3. min_samples_split    | strong positive correlation                    |negative correlation                           |\n",
    "|4. min_samples_leaf     | strong positive correlation                    |negative correlation                           |\n",
    "|5. min_weig_frac_leaf   | positively correlated                          |negatively correlated                          |\n",
    "|6. max_leaf_nodes       | negatively correlated                          |positively correlated                          |\n",
    "|7. min_impurity_decrease| positively correlated                          |negatively correlated                          |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f880b09",
   "metadata": {},
   "source": [
    "## 2. How does setting bootstrap=False influence the model performance? Note: the default is bootstrap=True. Explain why your results might be so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30127f8",
   "metadata": {},
   "source": [
    "#### Performance with default bootstrap = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17a3046d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 81.0 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       150\n",
      "           1       0.77      0.63      0.69        81\n",
      "\n",
      "    accuracy                           0.81       231\n",
      "   macro avg       0.80      0.76      0.78       231\n",
      "weighted avg       0.80      0.81      0.80       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200,random_state=6)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "print('Accuracy Score',rf.score(X_test, y_test).round(2)*100,'%')\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test,predictions))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44984ef",
   "metadata": {},
   "source": [
    "#### Performance with bootstrap = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83701483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 79.0 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       150\n",
      "           1       0.73      0.63      0.68        81\n",
      "\n",
      "    accuracy                           0.79       231\n",
      "   macro avg       0.77      0.75      0.76       231\n",
      "weighted avg       0.78      0.79      0.78       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap = False,n_estimators=200,random_state=6)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "print('Accuracy Score',rf.score(X_test, y_test).round(2)*100,'%')\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e600bc",
   "metadata": {},
   "source": [
    "#### Results discussion about setting bootstrap = False\n",
    "\n",
    "* Bootstrap is a boolean indicate whether samples are drawn with replacement. Default is True **(that is nature of bagging-(bootstrap aggregating))**. Some data points will be used more than once and others not.\n",
    "\n",
    "\n",
    "* If we set bootstrap = False, each estimator will be trained using every data exactly once.\n",
    "\n",
    "\n",
    "* In our class exercise Random Forest classifier with bootstrapping, it gave good accuracy and precision score. Because each classifier trained with Multiple bootstrap samples from the dataset, the mean calculated on each and gave a robust and accurate scores. With Bootstrapping = False, recall didn't change but precision and accuracy score reduced.\n",
    "\n",
    "\n",
    "* For this classifier, setting **bootstrap = True, performs well than bootstrap = False**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
